{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ML Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计每个元素的个数\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from hmmlearn.hmm import GaussianHMM\n",
    "\n",
    "from sklearn import svm\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    " \n",
    "def count(arr_gb):\n",
    "    arr_gb = pd.Series(arr_gb)       # 转换数据类型\n",
    "    arr_gb = arr_gb.value_counts()   # 计数\n",
    "    arr_gb.sort_index(inplace=True)  # 排序\n",
    "    return arr_gb\n",
    "\n",
    "def deal_with_fake_data(path):\n",
    "    X = np.array(pd.read_csv(path, sep=';'))\n",
    "    #  从 hours-per-week 这一列生成 labels\n",
    "    hours_per_week = X[:,-2]\n",
    "    mean_ = np.mean(hours_per_week)\n",
    "    y = []\n",
    "    for i in hours_per_week:\n",
    "        if i < mean_:\n",
    "            y.append(0)\n",
    "        else:\n",
    "            y.append(1)\n",
    "    y = np.array(y)\n",
    "    X = np.delete(X, -2, 1)\n",
    "    print(X.shape, y.shape)\n",
    "    print(\"labels 分布\")\n",
    "    print(count(y))\n",
    "    return X, y\n",
    "\n",
    "def split_data(X, y):\n",
    "    scaler = StandardScaler() # 标准化转换\n",
    "    scaler.fit(X)  # 训练标准化对象\n",
    "    X = scaler.transform(X)\n",
    "    return train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "#     return train_test_split(X, y, test_size=0.6)\n",
    "\n",
    "\n",
    "def result_compare(model):\n",
    "    if model == \"randomForest\":\n",
    "        model = RandomForestClassifier()\n",
    "    elif model == \"svm\":\n",
    "        model = svm.SVC()\n",
    "    elif model == \"reg\":\n",
    "        model = LogisticRegression()\n",
    "    elif model == \"gaussian\":\n",
    "        model = GaussianNB()\n",
    "    elif model == \"hmm\":\n",
    "        model = GaussianHMM()\n",
    "    else:\n",
    "        print(\"无法识别的模型名\")\n",
    "        return\n",
    "    \n",
    "    # ground truth\n",
    "    clf = model\n",
    "    clf.fit(X_real_train, y_real_train)\n",
    "    y_real_pred = clf.predict(X_real_test)\n",
    "    print(\"ground truth 的结果:\")\n",
    "    print(classification_report(y_real_test, y_real_pred))\n",
    "    print(\"--------------------------------------\")\n",
    "\n",
    "\n",
    "    # Original\n",
    "    clf = model\n",
    "    clf.fit(X_original_train, y_original_train)\n",
    "    y_original_pred = clf.predict(X_real_test)\n",
    "    print(\"Metric - Original 的结果:\")\n",
    "    print(classification_report(y_real_test, y_original_pred))\n",
    "    print(\"--------------------------------------\")\n",
    "\n",
    "\n",
    "    # New\n",
    "    clf = model\n",
    "    clf.fit(X_new_train, y_new_train)\n",
    "    y_new_pred = clf.predict(X_real_test)\n",
    "    print(\"Metric - New 的结果:\")\n",
    "    print(classification_report(y_real_test, y_new_pred))\n",
    "    print(\"--------------------------------------\")\n",
    "    \n",
    "    # New 3>,9>\n",
    "    clf = model\n",
    "    clf.fit(X_new2_train, y_new2_train)\n",
    "    y_new2_pred = clf.predict(X_real_test)\n",
    "    print(\"Metric - New 3>9> 的结果:\")\n",
    "    print(classification_report(y_real_test, y_new2_pred))\n",
    "    print(\"--------------------------------------\")\n",
    "    \n",
    "#     # Rule Data\n",
    "#     clf = model\n",
    "#     clf.fit(X_rule_data_train, y_rule_data_train)\n",
    "#     y_rule_data_pred = clf.predict(X_real_test)\n",
    "#     print(\"Metric - Rule Data 的结果:\")\n",
    "#     print(classification_report(y_real_test, y_rule_data_pred))\n",
    "#     print(\"--------------------------------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### REAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1999, 13) (1999,)\n",
      "labels 分布\n",
      "0    1389\n",
      "1     610\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "GROUND_TRUTH_X_PATH = \"/Users/luminshen/Documents/代码/PycharmProjects/Research/-GAN-/Table-GAN/tableGAN/data/Adult/Adult.csv\"\n",
    "GROUND_TRUTH_y_PATH = \"/Users/luminshen/Documents/代码/PycharmProjects/Research/-GAN-/Table-GAN/tableGAN/data/Adult/Adult_labels.csv\"\n",
    "\n",
    "X_real = np.array(pd.read_csv(GROUND_TRUTH_X_PATH, sep=',')[1:])\n",
    "y_real = np.array(pd.read_csv(GROUND_TRUTH_y_PATH, sep=',').astype(int)).flatten()\n",
    "#  去除 hours-per-week 这一列，因为它被用来生成 labels\n",
    "X_real = np.delete(X_real, -2, 1)\n",
    "print(X_real.shape, y_real.shape)\n",
    "print(\"labels 分布\")\n",
    "print(count(y_real))\n",
    "\n",
    "X_real_train, X_real_test, y_real_train, y_real_test = split_data(X_real, y_real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### FAKE-ORIGINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 13) (2000,)\n",
      "labels 分布\n",
      "0    1393\n",
      "1     607\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "FAKE_ORIGINAL_X_PATH = \"/Users/luminshen/Desktop/模型/original gan/300分钟/Adult_OI_11_00_fake.csv\"\n",
    "\n",
    "X_original, y_original = deal_with_fake_data(FAKE_ORIGINAL_X_PATH)\n",
    "X_original_train, X_original_test, y_original_train, y_original_test = split_data(X_original, y_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### new gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 13) (2000,)\n",
      "labels 分布\n",
      "0    1055\n",
      "1     945\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "FAKE_NEW_X_PATH = \"/Users/luminshen/Desktop/模型/new gan/0相同，10相同/600分钟 w2/Adult_OI_11_00_fake.csv\"\n",
    "\n",
    "X_new, y_new = deal_with_fake_data(FAKE_NEW_X_PATH)\n",
    "X_new_train, X_new_test, y_new_train, y_new_test = split_data(X_new, y_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### new gan 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 13) (2000,)\n",
      "labels 分布\n",
      "0    1012\n",
      "1     988\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "FAKE_NEW2_X_PATH = \"/Users/luminshen/Desktop/模型/new gan/3>, 9>/Adult_OI_11_00_fake.csv\"\n",
    "\n",
    "X_new2, y_new2 = deal_with_fake_data(FAKE_NEW2_X_PATH)\n",
    "X_new2_train, X_new2_test, y_new2_train, y_new2_test = split_data(X_new2, y_new2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### gan with data following rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 13) (200,)\n",
      "labels 分布\n",
      "0     96\n",
      "1    104\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "FAKE_RULE_DATA_X_PATH = \"/Users/luminshen/Desktop/模型/gan with data following rules/Adult_OI_11_00_fake.csv\"\n",
    "\n",
    "X_rule_data, y_rule_data = deal_with_fake_data(FAKE_RULE_DATA_X_PATH)\n",
    "X_rule_data_train, X_rule_data, y_rule_data_train, y_rule_data_test = split_data(X_rule_data, y_rule_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground truth 的结果:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.88      0.80       406\n",
      "           1       0.55      0.31      0.40       194\n",
      "\n",
      "    accuracy                           0.70       600\n",
      "   macro avg       0.64      0.60      0.60       600\n",
      "weighted avg       0.67      0.70      0.67       600\n",
      "\n",
      "--------------------------------------\n",
      "Metric - Original 的结果:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.96      0.79       406\n",
      "           1       0.33      0.04      0.07       194\n",
      "\n",
      "    accuracy                           0.66       600\n",
      "   macro avg       0.51      0.50      0.43       600\n",
      "weighted avg       0.57      0.66      0.56       600\n",
      "\n",
      "--------------------------------------\n",
      "Metric - New 的结果:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.62      0.63       406\n",
      "           1       0.28      0.31      0.29       194\n",
      "\n",
      "    accuracy                           0.52       600\n",
      "   macro avg       0.46      0.46      0.46       600\n",
      "weighted avg       0.53      0.52      0.52       600\n",
      "\n",
      "--------------------------------------\n",
      "Metric - New 3>9> 的结果:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.44      0.54       406\n",
      "           1       0.35      0.65      0.46       194\n",
      "\n",
      "    accuracy                           0.51       600\n",
      "   macro avg       0.54      0.54      0.50       600\n",
      "weighted avg       0.60      0.51      0.52       600\n",
      "\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "result_compare(\"randomForest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground truth 的结果:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.90      0.79       406\n",
      "           1       0.51      0.21      0.30       194\n",
      "\n",
      "    accuracy                           0.68       600\n",
      "   macro avg       0.61      0.56      0.55       600\n",
      "weighted avg       0.64      0.68      0.63       600\n",
      "\n",
      "--------------------------------------\n",
      "Metric - Original 的结果:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.55      0.60       406\n",
      "           1       0.29      0.38      0.33       194\n",
      "\n",
      "    accuracy                           0.50       600\n",
      "   macro avg       0.47      0.47      0.46       600\n",
      "weighted avg       0.53      0.50      0.51       600\n",
      "\n",
      "--------------------------------------\n",
      "Metric - New 的结果:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.58      0.63       406\n",
      "           1       0.33      0.43      0.37       194\n",
      "\n",
      "    accuracy                           0.53       600\n",
      "   macro avg       0.51      0.51      0.50       600\n",
      "weighted avg       0.57      0.53      0.54       600\n",
      "\n",
      "--------------------------------------\n",
      "Metric - New 3>9> 的结果:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.48      0.58       406\n",
      "           1       0.36      0.60      0.45       194\n",
      "\n",
      "    accuracy                           0.52       600\n",
      "   macro avg       0.54      0.54      0.51       600\n",
      "weighted avg       0.60      0.52      0.53       600\n",
      "\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "result_compare( \"svm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground truth 的结果:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.91      0.79       406\n",
      "           1       0.50      0.19      0.28       194\n",
      "\n",
      "    accuracy                           0.68       600\n",
      "   macro avg       0.60      0.55      0.53       600\n",
      "weighted avg       0.64      0.68      0.63       600\n",
      "\n",
      "--------------------------------------\n",
      "Metric - Original 的结果:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.64      0.65       406\n",
      "           1       0.31      0.34      0.32       194\n",
      "\n",
      "    accuracy                           0.54       600\n",
      "   macro avg       0.49      0.49      0.49       600\n",
      "weighted avg       0.55      0.54      0.55       600\n",
      "\n",
      "--------------------------------------\n",
      "Metric - New 的结果:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.56      0.61       406\n",
      "           1       0.30      0.39      0.34       194\n",
      "\n",
      "    accuracy                           0.51       600\n",
      "   macro avg       0.48      0.47      0.47       600\n",
      "weighted avg       0.54      0.51      0.52       600\n",
      "\n",
      "--------------------------------------\n",
      "Metric - New 3>9> 的结果:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.55      0.63       406\n",
      "           1       0.38      0.57      0.46       194\n",
      "\n",
      "    accuracy                           0.56       600\n",
      "   macro avg       0.56      0.56      0.54       600\n",
      "weighted avg       0.62      0.56      0.57       600\n",
      "\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "result_compare(\"reg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground truth 的结果:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.78      0.75       406\n",
      "           1       0.46      0.40      0.43       194\n",
      "\n",
      "    accuracy                           0.66       600\n",
      "   macro avg       0.60      0.59      0.59       600\n",
      "weighted avg       0.65      0.66      0.65       600\n",
      "\n",
      "--------------------------------------\n",
      "Metric - Original 的结果:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.90      0.77       406\n",
      "           1       0.26      0.07      0.11       194\n",
      "\n",
      "    accuracy                           0.64       600\n",
      "   macro avg       0.47      0.49      0.44       600\n",
      "weighted avg       0.54      0.64      0.56       600\n",
      "\n",
      "--------------------------------------\n",
      "Metric - New 的结果:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.34      0.45       406\n",
      "           1       0.30      0.60      0.40       194\n",
      "\n",
      "    accuracy                           0.43       600\n",
      "   macro avg       0.47      0.47      0.43       600\n",
      "weighted avg       0.53      0.43      0.43       600\n",
      "\n",
      "--------------------------------------\n",
      "Metric - New 3>9> 的结果:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.79      0.72       406\n",
      "           1       0.29      0.18      0.22       194\n",
      "\n",
      "    accuracy                           0.59       600\n",
      "   macro avg       0.48      0.48      0.47       600\n",
      "weighted avg       0.54      0.59      0.56       600\n",
      "\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "result_compare(\"gaussian\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "def get_kldiverge(data_1, data_2):\n",
    "    if data_1.split(\"/\")[-1] == \"Adult.csv\":\n",
    "        A = np.array(pd.read_csv(data_1, sep=',')).astype(float)\n",
    "    else:\n",
    "        A = np.array(pd.read_csv(data_1, sep=';')).astype(float)\n",
    "        \n",
    "    if data_2.split(\"/\")[-1] == \"Adult.csv\":\n",
    "        B = np.array(pd.read_csv(data_2, sep=',')).astype(float)\n",
    "    else:\n",
    "        B = np.array(pd.read_csv(data_2, sep=';')).astype(float)\n",
    "\n",
    "    KL = scipy.stats.entropy(A, B) \n",
    "    \n",
    "#     print(KL)\n",
    "    \n",
    "    res = 0\n",
    "    count = 0\n",
    "    for kl in KL:\n",
    "        if kl != float('inf'):\n",
    "            res += kl\n",
    "            count += 1\n",
    "            \n",
    "    return res/count\n",
    "\n",
    "def get_mse(data_1, data_2):\n",
    "    if data_1.split(\"/\")[-1] == \"Adult.csv\":\n",
    "        A = np.array(pd.read_csv(data_1, sep=',')).astype(float)\n",
    "    else:\n",
    "        A = np.array(pd.read_csv(data_1, sep=';')).astype(float)\n",
    "        \n",
    "    if data_2.split(\"/\")[-1] == \"Adult.csv\":\n",
    "        B = np.array(pd.read_csv(data_2, sep=',')).astype(float)\n",
    "    else:\n",
    "        B = np.array(pd.read_csv(data_2, sep=';')).astype(float)\n",
    "    \n",
    "#     print(A.shape, B.shape)\n",
    "    X = np.append(A, B, axis=0)\n",
    "    y = np.append(np.zeros(A.shape[0]), np.ones(B.shape[0]))\n",
    "#     print(X.shape, y.shape)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7, random_state=1)\n",
    "\n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict_proba(X_test)\n",
    "    \n",
    "    # 计算 MSE\n",
    "#     print(count(y_test))\n",
    "    c = 1395/2800\n",
    "    res = 0\n",
    "    for i in range(X.shape[0]):\n",
    "        res += (y_pred[0][0] - c)**2\n",
    "    \n",
    "    print(res/X.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### kl diverge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20904159718322513\n",
      "0.2201262291237125\n",
      "0.22591861288510268\n"
     ]
    }
   ],
   "source": [
    "GROUND_TRUTH_PATH = \"/Users/luminshen/Documents/代码/PycharmProjects/Research/-GAN-/Table-GAN/tableGAN/data/Adult/Adult.csv\"\n",
    "FAKE_ORIGINAL_PATH = \"/Users/luminshen/Desktop/模型/original gan/300分钟/Adult_OI_11_00_fake.csv\"\n",
    "FAKE_NEW_PATH = \"/Users/luminshen/Desktop/模型/new gan/0相同，10相同/600分钟 w2/Adult_OI_11_00_fake.csv\"\n",
    "FAKE_NEW2_PATH = \"/Users/luminshen/Desktop/模型/new gan/3>, 9>/Adult_OI_11_00_fake.csv\"\n",
    "\n",
    "print(get_kldiverge(GROUND_TRUTH_PATH, FAKE_ORIGINAL_PATH))\n",
    "print(get_kldiverge(GROUND_TRUTH_PATH, FAKE_NEW_PATH))\n",
    "print(get_kldiverge(GROUND_TRUTH_PATH, FAKE_NEW2_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Propensity Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25163943621930857\n",
      "0.07102413027610538\n",
      "0.14479387365956412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luminshen/Documents/代码/PycharmProjects/Research/-GAN-/venv/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "get_mse(GROUND_TRUTH_PATH, FAKE_ORIGINAL_PATH)\n",
    "get_mse(GROUND_TRUTH_PATH, FAKE_NEW_PATH)\n",
    "get_mse(GROUND_TRUTH_PATH, FAKE_NEW2_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
