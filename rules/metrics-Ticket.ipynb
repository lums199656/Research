{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ML Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计每个元素的个数\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from hmmlearn.hmm import GaussianHMM\n",
    "\n",
    "from sklearn import svm\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    " \n",
    "def count(arr_gb):\n",
    "    arr_gb = pd.Series(arr_gb)       # 转换数据类型\n",
    "    arr_gb = arr_gb.value_counts()   # 计数\n",
    "    arr_gb.sort_index(inplace=True)  # 排序\n",
    "    return arr_gb\n",
    "\n",
    "def deal_with_fake_data(path):\n",
    "    X = np.array(pd.read_csv(path, sep=';'))\n",
    "    #  从 hours-per-week 这一列生成 labels\n",
    "    hours_per_week = X[:,-2]\n",
    "    mean_ = np.mean(hours_per_week)\n",
    "    y = []\n",
    "    for i in hours_per_week:\n",
    "        if i < mean_:\n",
    "            y.append(0)\n",
    "        else:\n",
    "            y.append(1)\n",
    "    y = np.array(y)\n",
    "    X = np.delete(X, -2, 1)\n",
    "    print(X.shape, y.shape)\n",
    "    print(\"labels 分布\")\n",
    "    print(count(y))\n",
    "    return X, y\n",
    "\n",
    "def deal_with_real_data(path):\n",
    "    X = np.array(pd.read_csv(path, sep=','))\n",
    "    #  从 hours-per-week 这一列生成 labels\n",
    "    hours_per_week = X[:,-2]\n",
    "    mean_ = np.mean(hours_per_week)\n",
    "    y = []\n",
    "    for i in hours_per_week:\n",
    "        if i < mean_:\n",
    "            y.append(0)\n",
    "        else:\n",
    "            y.append(1)\n",
    "    y = np.array(y)\n",
    "    X = np.delete(X, -2, 1)\n",
    "    print(X.shape, y.shape)\n",
    "    print(\"labels 分布\")\n",
    "    print(count(y))\n",
    "    return X, y\n",
    "\n",
    "def split_data(X, y):\n",
    "    scaler = StandardScaler() # 标准化转换\n",
    "    scaler.fit(X)  # 训练标准化对象\n",
    "    X = scaler.transform(X)\n",
    "#     return train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "    return train_test_split(X, y, test_size=0.4)\n",
    "\n",
    "\n",
    "def result_compare(model):\n",
    "    if model == \"randomForest\":\n",
    "        model = RandomForestClassifier()\n",
    "    elif model == \"svm\":\n",
    "        model = svm.SVC()\n",
    "    elif model == \"reg\":\n",
    "        model = LogisticRegression()\n",
    "    elif model == \"gaussian\":\n",
    "        model = GaussianNB()\n",
    "    elif model == \"hmm\":\n",
    "        model = GaussianHMM()\n",
    "    else:\n",
    "        print(\"无法识别的模型名\")\n",
    "        return\n",
    "    \n",
    "    # ground truth\n",
    "    clf = model\n",
    "    clf.fit(X_real_train, y_real_train)\n",
    "    y_real_pred = clf.predict(X_real_test)\n",
    "    print(\"ground truth 的结果:\")\n",
    "    print(classification_report(y_real_test, y_real_pred))\n",
    "    print(\"--------------------------------------\")\n",
    "\n",
    "\n",
    "    # Original\n",
    "    clf = model\n",
    "    clf.fit(X_original_train, y_original_train)\n",
    "    y_original_pred = clf.predict(X_real_test)\n",
    "    print(\"Metric - Original 的结果:\")\n",
    "    print(classification_report(y_real_test, y_original_pred))\n",
    "    print(\"--------------------------------------\")\n",
    "\n",
    "\n",
    "    # New\n",
    "    clf = model\n",
    "    clf.fit(X_new_train, y_new_train)\n",
    "    y_new_pred = clf.predict(X_real_test)\n",
    "    print(\"Metric - New 的结果:\")\n",
    "    print(classification_report(y_real_test, y_new_pred))\n",
    "    print(\"--------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### REAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 13) (2000,)\n",
      "labels 分布\n",
      "0    1105\n",
      "1     895\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "GROUND_TRUTH_X_PATH = \"/Users/luminshen/Documents/代码/PycharmProjects/Research/-GAN-/Table-GAN/tableGAN/data/Ticket/Ticket.csv\"\n",
    "# GROUND_TRUTH_y_PATH = \"/Users/luminshen/Documents/代码/PycharmProjects/Research/-GAN-/Table-GAN/tableGAN/data/Ticket/Ticket_labels.csv\"\n",
    "\n",
    "X_real, y_real = deal_with_real_data(GROUND_TRUTH_X_PATH)\n",
    "X_real_train, X_real_test, y_real_train, y_real_test = split_data(X_real, y_real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### FAKE-ORIGINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 13) (2000,)\n",
      "labels 分布\n",
      "0    1222\n",
      "1     778\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "FAKE_ORIGINAL_X_PATH = \"/Users/luminshen/Documents/代码/PycharmProjects/Research/-GAN-/Table-GAN/tableGAN/samples/Ticket/Ticket_OI_11_00_fake.csv\"\n",
    "\n",
    "X_original, y_original = deal_with_fake_data(FAKE_ORIGINAL_X_PATH)\n",
    "X_original_train, X_original_test, y_original_train, y_original_test = split_data(X_original, y_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### new gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 13) (2000,)\n",
      "labels 分布\n",
      "0    1143\n",
      "1     857\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "FAKE_NEW_X_PATH = \"/Users/luminshen/Desktop/模型/new gan/T-3>9>/Ticket_OI_11_00_fake.csv\"\n",
    "\n",
    "X_new, y_new = deal_with_fake_data(FAKE_NEW_X_PATH)\n",
    "X_new_train, X_new_test, y_new_train, y_new_test = split_data(X_new, y_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground truth 的结果:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       445\n",
      "           1       0.97      0.95      0.96       355\n",
      "\n",
      "    accuracy                           0.97       800\n",
      "   macro avg       0.97      0.97      0.97       800\n",
      "weighted avg       0.97      0.97      0.97       800\n",
      "\n",
      "--------------------------------------\n",
      "Metric - Original 的结果:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.73      0.69       445\n",
      "           1       0.61      0.52      0.56       355\n",
      "\n",
      "    accuracy                           0.64       800\n",
      "   macro avg       0.63      0.63      0.63       800\n",
      "weighted avg       0.63      0.64      0.63       800\n",
      "\n",
      "--------------------------------------\n",
      "Metric - New 的结果:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.71      0.75       445\n",
      "           1       0.68      0.76      0.72       355\n",
      "\n",
      "    accuracy                           0.73       800\n",
      "   macro avg       0.73      0.74      0.73       800\n",
      "weighted avg       0.74      0.73      0.73       800\n",
      "\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "result_compare(\"randomForest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground truth 的结果:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.92       445\n",
      "           1       0.98      0.81      0.89       355\n",
      "\n",
      "    accuracy                           0.91       800\n",
      "   macro avg       0.92      0.90      0.91       800\n",
      "weighted avg       0.92      0.91      0.91       800\n",
      "\n",
      "--------------------------------------\n",
      "Metric - Original 的结果:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.67      0.66       445\n",
      "           1       0.57      0.55      0.56       355\n",
      "\n",
      "    accuracy                           0.62       800\n",
      "   macro avg       0.61      0.61      0.61       800\n",
      "weighted avg       0.62      0.62      0.62       800\n",
      "\n",
      "--------------------------------------\n",
      "Metric - New 的结果:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.80      0.77       445\n",
      "           1       0.72      0.65      0.68       355\n",
      "\n",
      "    accuracy                           0.73       800\n",
      "   macro avg       0.73      0.72      0.72       800\n",
      "weighted avg       0.73      0.73      0.73       800\n",
      "\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "result_compare( \"svm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground truth 的结果:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.97      0.88       445\n",
      "           1       0.95      0.72      0.82       355\n",
      "\n",
      "    accuracy                           0.86       800\n",
      "   macro avg       0.88      0.84      0.85       800\n",
      "weighted avg       0.87      0.86      0.85       800\n",
      "\n",
      "--------------------------------------\n",
      "Metric - Original 的结果:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.77      0.75       445\n",
      "           1       0.69      0.63      0.66       355\n",
      "\n",
      "    accuracy                           0.71       800\n",
      "   macro avg       0.71      0.70      0.70       800\n",
      "weighted avg       0.71      0.71      0.71       800\n",
      "\n",
      "--------------------------------------\n",
      "Metric - New 的结果:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.82      0.77       445\n",
      "           1       0.74      0.62      0.67       355\n",
      "\n",
      "    accuracy                           0.73       800\n",
      "   macro avg       0.73      0.72      0.72       800\n",
      "weighted avg       0.73      0.73      0.73       800\n",
      "\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "result_compare(\"reg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground truth 的结果:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.86      0.87       445\n",
      "           1       0.83      0.87      0.85       355\n",
      "\n",
      "    accuracy                           0.86       800\n",
      "   macro avg       0.86      0.86      0.86       800\n",
      "weighted avg       0.86      0.86      0.86       800\n",
      "\n",
      "--------------------------------------\n",
      "Metric - Original 的结果:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.77      0.76       445\n",
      "           1       0.70      0.66      0.68       355\n",
      "\n",
      "    accuracy                           0.72       800\n",
      "   macro avg       0.72      0.72      0.72       800\n",
      "weighted avg       0.72      0.72      0.72       800\n",
      "\n",
      "--------------------------------------\n",
      "Metric - New 的结果:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.94      0.80       445\n",
      "           1       0.86      0.47      0.61       355\n",
      "\n",
      "    accuracy                           0.73       800\n",
      "   macro avg       0.78      0.70      0.70       800\n",
      "weighted avg       0.77      0.73      0.71       800\n",
      "\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "result_compare(\"gaussian\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "def get_kldiverge(data_1, data_2):\n",
    "    if data_1.split(\"/\")[-1] == \"Ticket.csv\":\n",
    "        A = np.array(pd.read_csv(data_1, sep=',')).astype(float)\n",
    "    else:\n",
    "        A = np.array(pd.read_csv(data_1, sep=';')).astype(float)\n",
    "        \n",
    "    if data_2.split(\"/\")[-1] == \"Ticket.csv\":\n",
    "        B = np.array(pd.read_csv(data_2, sep=',')).astype(float)\n",
    "    else:\n",
    "        B = np.array(pd.read_csv(data_2, sep=';')).astype(float)\n",
    "\n",
    "    KL = scipy.stats.entropy(A, B) \n",
    "    \n",
    "#     print(KL)\n",
    "    \n",
    "    res = 0\n",
    "    count = 0\n",
    "    for kl in KL:\n",
    "        if (not np.isnan(kl)) and (kl != np.float(\"inf\")):\n",
    "            res += kl\n",
    "            count += 1\n",
    "            \n",
    "    return res/count\n",
    "\n",
    "def get_mse(data_1, data_2):\n",
    "    if data_1.split(\"/\")[-1] == \"Ticket.csv\":\n",
    "        A = np.array(pd.read_csv(data_1, sep=',')).astype(float)\n",
    "    else:\n",
    "        A = np.array(pd.read_csv(data_1, sep=';')).astype(float)\n",
    "        \n",
    "    if data_2.split(\"/\")[-1] == \"Ticket.csv\":\n",
    "        B = np.array(pd.read_csv(data_2, sep=',')).astype(float)\n",
    "    else:\n",
    "        B = np.array(pd.read_csv(data_2, sep=';')).astype(float)\n",
    "    \n",
    "#     print(A.shape, B.shape)\n",
    "    X = np.append(A, B, axis=0)\n",
    "    y = np.append(np.zeros(A.shape[0]), np.ones(B.shape[0]))\n",
    "#     print(X.shape, y.shape)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict_proba(X_test)\n",
    "    \n",
    "    # 计算 MSE\n",
    "    c = 616/(584+616)\n",
    "    res = 0\n",
    "    for i in range(X.shape[0]):\n",
    "        res += (y_pred[0][0] - c)**2\n",
    "    \n",
    "    print(res/X.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### kl diverge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35653191205703677\n",
      "0.474644305902042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luminshen/Documents/代码/PycharmProjects/Research/-GAN-/venv/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:2751: RuntimeWarning: invalid value encountered in true_divide\n",
      "  pk = 1.0*pk / np.sum(pk, axis=axis, keepdims=True)\n",
      "/Users/luminshen/Documents/代码/PycharmProjects/Research/-GAN-/venv/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:2758: RuntimeWarning: invalid value encountered in true_divide\n",
      "  qk = 1.0*qk / np.sum(qk, axis=axis, keepdims=True)\n"
     ]
    }
   ],
   "source": [
    "GROUND_TRUTH_PATH = \"/Users/luminshen/Documents/代码/PycharmProjects/Research/-GAN-/Table-GAN/tableGAN/data/Ticket/Ticket.csv\"\n",
    "FAKE_ORIGINAL_PATH = \"/Users/luminshen/Documents/代码/PycharmProjects/Research/-GAN-/Table-GAN/tableGAN/samples/Ticket/Ticket_OI_11_00_fake.csv\"\n",
    "FAKE_NEW_PATH = \"/Users/luminshen/Desktop/模型/new gan/T-3>9>/Ticket_OI_11_00_fake.csv\"\n",
    "\n",
    "print(get_kldiverge(GROUND_TRUTH_PATH, FAKE_ORIGINAL_PATH))\n",
    "print(get_kldiverge(GROUND_TRUTH_PATH, FAKE_NEW_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Propensity Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1475889411332195\n",
      "0.11697347529745791\n"
     ]
    }
   ],
   "source": [
    "get_mse(GROUND_TRUTH_PATH, FAKE_ORIGINAL_PATH)\n",
    "get_mse(GROUND_TRUTH_PATH, FAKE_NEW_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
