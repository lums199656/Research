{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ML Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计每个元素的个数\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    " \n",
    "def count(arr_gb):\n",
    "    arr_gb = pd.Series(arr_gb)       # 转换数据类型\n",
    "    arr_gb = arr_gb.value_counts()   # 计数\n",
    "    arr_gb.sort_index(inplace=True)  # 排序\n",
    "    return arr_gb\n",
    "\n",
    "def deal_with_fake_data(path):\n",
    "    X = np.array(pd.read_csv(path, sep=';'))\n",
    "    #  从 hours-per-week 这一列生成 labels\n",
    "    hours_per_week = X[:,-2]\n",
    "    mean_ = np.mean(hours_per_week)\n",
    "    y = []\n",
    "    for i in hours_per_week:\n",
    "        if i < mean_:\n",
    "            y.append(0)\n",
    "        else:\n",
    "            y.append(1)\n",
    "    y = np.array(y)\n",
    "    X = np.delete(X, -2, 1)\n",
    "    print(X.shape, y.shape)\n",
    "    print(\"labels 分布\")\n",
    "    print(count(y))\n",
    "    return X, y\n",
    "\n",
    "def split_data(X, y):\n",
    "    scaler = StandardScaler() # 标准化转换\n",
    "    scaler.fit(X)  # 训练标准化对象\n",
    "    X = scaler.transform(X)\n",
    "    return train_test_split(X, y, test_size=0.5, random_state=1)\n",
    "\n",
    "def result_compare(model):\n",
    "    if model == \"randomForest\":\n",
    "        model = RandomForestClassifier()\n",
    "    elif model == \"svm\":\n",
    "        model = svm.SVC()\n",
    "    elif model == \"reg\":\n",
    "        model = LogisticRegression()\n",
    "    else:\n",
    "        print(\"无法识别的模型名\")\n",
    "        return\n",
    "    \n",
    "    # ground truth\n",
    "    clf = model\n",
    "    clf.fit(X_real_train, y_real_train)\n",
    "    y_real_pred = clf.predict(X_real_test)\n",
    "    print(\"ground truth 的结果:\")\n",
    "    print(classification_report(y_real_test, y_real_pred))\n",
    "    print(\"--------------------------------------\")\n",
    "\n",
    "\n",
    "    # Original\n",
    "    clf = model\n",
    "    clf.fit(X_original_train, y_original_train)\n",
    "    y_original_pred = clf.predict(X_real_test)\n",
    "    print(\"Metric - Original 的结果:\")\n",
    "    print(classification_report(y_real_test, y_original_pred))\n",
    "    print(\"--------------------------------------\")\n",
    "\n",
    "\n",
    "    # New\n",
    "    clf = model\n",
    "    clf.fit(X_new_train, y_new_train)\n",
    "    y_new_pred = clf.predict(X_real_test)\n",
    "    print(\"Metric - New 的结果:\")\n",
    "    print(classification_report(y_real_test, y_new_pred))\n",
    "    print(\"--------------------------------------\")\n",
    "    \n",
    "    # New 3>,9>\n",
    "    clf = model\n",
    "    clf.fit(X_new2_train, y_new2_train)\n",
    "    y_new2_pred = clf.predict(X_real_test)\n",
    "    print(\"Metric - New 3>9> 的结果:\")\n",
    "    print(classification_report(y_real_test, y_new2_pred))\n",
    "    print(\"--------------------------------------\")\n",
    "    \n",
    "#     # Rule Data\n",
    "#     clf = model\n",
    "#     clf.fit(X_rule_data_train, y_rule_data_train)\n",
    "#     y_rule_data_pred = clf.predict(X_real_test)\n",
    "#     print(\"Metric - Rule Data 的结果:\")\n",
    "#     print(classification_report(y_real_test, y_rule_data_pred))\n",
    "#     print(\"--------------------------------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### REAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1999, 13) (1999,)\n",
      "labels 分布\n",
      "0    1389\n",
      "1     610\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "GROUND_TRUTH_X_PATH = \"/Users/luminshen/Documents/代码/PycharmProjects/Research/-GAN-/Table-GAN/tableGAN/data/Adult/Adult.csv\"\n",
    "GROUND_TRUTH_y_PATH = \"/Users/luminshen/Documents/代码/PycharmProjects/Research/-GAN-/Table-GAN/tableGAN/data/Adult/Adult_labels.csv\"\n",
    "\n",
    "X_real = np.array(pd.read_csv(GROUND_TRUTH_X_PATH, sep=',')[1:])\n",
    "y_real = np.array(pd.read_csv(GROUND_TRUTH_y_PATH, sep=',').astype(int)).flatten()\n",
    "#  去除 hours-per-week 这一列，因为它被用来生成 labels\n",
    "X_real = np.delete(X_real, -2, 1)\n",
    "print(X_real.shape, y_real.shape)\n",
    "print(\"labels 分布\")\n",
    "print(count(y_real))\n",
    "\n",
    "X_real_train, X_real_test, y_real_train, y_real_test = split_data(X_real, y_real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### FAKE-ORIGINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 13) (2000,)\n",
      "labels 分布\n",
      "0    1393\n",
      "1     607\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "FAKE_ORIGINAL_X_PATH = \"/Users/luminshen/Desktop/模型/original gan/300分钟/Adult_OI_11_00_fake.csv\"\n",
    "\n",
    "X_original, y_original = deal_with_fake_data(FAKE_ORIGINAL_X_PATH)\n",
    "X_original_train, X_original_test, y_original_train, y_original_test = split_data(X_original, y_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### new gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 13) (2000,)\n",
      "labels 分布\n",
      "0    1055\n",
      "1     945\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "FAKE_NEW_X_PATH = \"/Users/luminshen/Desktop/模型/new gan/0相同，10相同/600分钟 w2/Adult_OI_11_00_fake.csv\"\n",
    "\n",
    "X_new, y_new = deal_with_fake_data(FAKE_NEW_X_PATH)\n",
    "X_new_train, X_new_test, y_new_train, y_new_test = split_data(X_new, y_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### new gan 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 13) (2000,)\n",
      "labels 分布\n",
      "0    1012\n",
      "1     988\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "FAKE_NEW2_X_PATH = \"/Users/luminshen/Desktop/模型/new gan/3>, 9>/Adult_OI_11_00_fake.csv\"\n",
    "\n",
    "X_new2, y_new2 = deal_with_fake_data(FAKE_NEW2_X_PATH)\n",
    "X_new2_train, X_new2_test, y_new2_train, y_new2_test = split_data(X_new2, y_new2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### gan with data following rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 13) (200,)\n",
      "labels 分布\n",
      "0     96\n",
      "1    104\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "FAKE_RULE_DATA_X_PATH = \"/Users/luminshen/Desktop/模型/gan with data following rules/Adult_OI_11_00_fake.csv\"\n",
    "\n",
    "X_rule_data, y_rule_data = deal_with_fake_data(FAKE_RULE_DATA_X_PATH)\n",
    "X_rule_data_train, X_rule_data, y_rule_data_train, y_rule_data_test = split_data(X_rule_data, y_rule_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground truth 的结果:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.87      0.81       689\n",
      "           1       0.58      0.39      0.47       311\n",
      "\n",
      "    accuracy                           0.72      1000\n",
      "   macro avg       0.67      0.63      0.64      1000\n",
      "weighted avg       0.71      0.72      0.71      1000\n",
      "\n",
      "--------------------------------------\n",
      "Metric - Original 的结果:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.98      0.81       689\n",
      "           1       0.26      0.02      0.03       311\n",
      "\n",
      "    accuracy                           0.68      1000\n",
      "   macro avg       0.48      0.50      0.42      1000\n",
      "weighted avg       0.56      0.68      0.57      1000\n",
      "\n",
      "--------------------------------------\n",
      "Metric - New 的结果:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.63      0.65       689\n",
      "           1       0.26      0.29      0.27       311\n",
      "\n",
      "    accuracy                           0.52      1000\n",
      "   macro avg       0.46      0.46      0.46      1000\n",
      "weighted avg       0.54      0.52      0.53      1000\n",
      "\n",
      "--------------------------------------\n",
      "Metric - New 3>9> 的结果:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.52      0.62       689\n",
      "           1       0.36      0.60      0.45       311\n",
      "\n",
      "    accuracy                           0.55      1000\n",
      "   macro avg       0.56      0.56      0.54      1000\n",
      "weighted avg       0.63      0.55      0.57      1000\n",
      "\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "result_compare(\"randomForest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground truth 的结果:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.94      0.81       689\n",
      "           1       0.52      0.15      0.24       311\n",
      "\n",
      "    accuracy                           0.69      1000\n",
      "   macro avg       0.62      0.55      0.52      1000\n",
      "weighted avg       0.65      0.69      0.63      1000\n",
      "\n",
      "--------------------------------------\n",
      "Metric - Original 的结果:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.61      0.63       689\n",
      "           1       0.27      0.32      0.29       311\n",
      "\n",
      "    accuracy                           0.52      1000\n",
      "   macro avg       0.46      0.46      0.46      1000\n",
      "weighted avg       0.54      0.52      0.53      1000\n",
      "\n",
      "--------------------------------------\n",
      "Metric - New 的结果:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.58      0.63       689\n",
      "           1       0.30      0.41      0.35       311\n",
      "\n",
      "    accuracy                           0.53      1000\n",
      "   macro avg       0.49      0.49      0.49      1000\n",
      "weighted avg       0.56      0.53      0.54      1000\n",
      "\n",
      "--------------------------------------\n",
      "Metric - New 3>9> 的结果:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.51      0.61       689\n",
      "           1       0.37      0.63      0.46       311\n",
      "\n",
      "    accuracy                           0.55      1000\n",
      "   macro avg       0.56      0.57      0.53      1000\n",
      "weighted avg       0.63      0.55      0.56      1000\n",
      "\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "result_compare( \"svm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground truth 的结果:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.89      0.80       689\n",
      "           1       0.50      0.24      0.33       311\n",
      "\n",
      "    accuracy                           0.69      1000\n",
      "   macro avg       0.61      0.57      0.56      1000\n",
      "weighted avg       0.65      0.69      0.65      1000\n",
      "\n",
      "--------------------------------------\n",
      "Metric - Original 的结果:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.65      0.66       689\n",
      "           1       0.30      0.33      0.31       311\n",
      "\n",
      "    accuracy                           0.55      1000\n",
      "   macro avg       0.49      0.49      0.49      1000\n",
      "weighted avg       0.56      0.55      0.55      1000\n",
      "\n",
      "--------------------------------------\n",
      "Metric - New 的结果:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.60      0.64       689\n",
      "           1       0.31      0.41      0.35       311\n",
      "\n",
      "    accuracy                           0.54      1000\n",
      "   macro avg       0.50      0.50      0.50      1000\n",
      "weighted avg       0.57      0.54      0.55      1000\n",
      "\n",
      "--------------------------------------\n",
      "Metric - New 3>9> 的结果:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.53      0.62       689\n",
      "           1       0.36      0.59      0.45       311\n",
      "\n",
      "    accuracy                           0.55      1000\n",
      "   macro avg       0.55      0.56      0.54      1000\n",
      "weighted avg       0.63      0.55      0.57      1000\n",
      "\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "result_compare(\"reg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_kldiverge(data_1, data_2):\n",
    "    if data_1.split(\"/\")[-1] == \"Adult.csv\":\n",
    "        A = np.array(pd.read_csv(data_1, sep=',')).astype(float)\n",
    "    else:\n",
    "        A = np.array(pd.read_csv(data_1, sep=';')).astype(float)\n",
    "        \n",
    "    if data_2.split(\"/\")[-1] == \"Adult.csv\":\n",
    "        B = np.array(pd.read_csv(data_2, sep=',')).astype(float)\n",
    "    else:\n",
    "        B = np.array(pd.read_csv(data_2, sep=';')).astype(float)\n",
    "\n",
    "    KL = scipy.stats.entropy(A, B) \n",
    "    \n",
    "#     print(KL)\n",
    "    \n",
    "    res = 0\n",
    "    count = 0\n",
    "    for kl in KL:\n",
    "        if kl != float('inf'):\n",
    "            res += kl\n",
    "            count += 1\n",
    "            \n",
    "    return res/count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### kl diverge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scipy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-71360d51c84f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mFAKE_NEW2_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/Users/luminshen/Desktop/模型/new gan/3>, 9>/Adult_OI_11_00_fake.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_kldiverge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGROUND_TRUTH_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFAKE_ORIGINAL_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_kldiverge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGROUND_TRUTH_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFAKE_NEW_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_kldiverge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGROUND_TRUTH_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFAKE_NEW2_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-fed2cc2550fc>\u001b[0m in \u001b[0;36mget_kldiverge\u001b[0;34m(data_1, data_2)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m';'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mKL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m#     print(KL)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scipy' is not defined"
     ]
    }
   ],
   "source": [
    "GROUND_TRUTH_PATH = \"/Users/luminshen/Documents/代码/PycharmProjects/Research/-GAN-/Table-GAN/tableGAN/data/Adult/Adult.csv\"\n",
    "FAKE_ORIGINAL_PATH = \"/Users/luminshen/Desktop/模型/original gan/300分钟/Adult_OI_11_00_fake.csv\"\n",
    "FAKE_NEW_PATH = \"/Users/luminshen/Desktop/模型/new gan/0相同，10相同/600分钟 w2/Adult_OI_11_00_fake.csv\"\n",
    "FAKE_NEW2_PATH = \"/Users/luminshen/Desktop/模型/new gan/3>, 9>/Adult_OI_11_00_fake.csv\"\n",
    "\n",
    "print(get_kldiverge(GROUND_TRUTH_PATH, FAKE_ORIGINAL_PATH))\n",
    "print(get_kldiverge(GROUND_TRUTH_PATH, FAKE_NEW_PATH))\n",
    "print(get_kldiverge(GROUND_TRUTH_PATH, FAKE_NEW2_PATH))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
