{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ML Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计每个元素的个数\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from hmmlearn.hmm import GaussianHMM\n",
    "\n",
    "from sklearn import svm\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    " \n",
    "def count(arr_gb):\n",
    "    arr_gb = pd.Series(arr_gb)       # 转换数据类型\n",
    "    arr_gb = arr_gb.value_counts()   # 计数\n",
    "    arr_gb.sort_index(inplace=True)  # 排序\n",
    "    return arr_gb\n",
    "\n",
    "def deal_with_fake_data(path):\n",
    "    X = np.array(pd.read_csv(path, sep=';'))\n",
    "    #  从 hours-per-week 这一列生成 labels\n",
    "    hours_per_week = X[:,-2]\n",
    "    mean_ = np.mean(hours_per_week)\n",
    "    y = []\n",
    "    for i in hours_per_week:\n",
    "        if i < mean_:\n",
    "            y.append(0)\n",
    "        else:\n",
    "            y.append(1)\n",
    "    y = np.array(y)\n",
    "    X = np.delete(X, -2, 1)\n",
    "    print(X.shape, y.shape)\n",
    "    print(\"labels 分布\")\n",
    "    print(count(y))\n",
    "    return X, y\n",
    "\n",
    "def split_data(X, y):\n",
    "    scaler = StandardScaler() # 标准化转换\n",
    "    scaler.fit(X)  # 训练标准化对象\n",
    "    X = scaler.transform(X)\n",
    "#     return train_test_split(X, y, test_size=0.5, random_state=1)\n",
    "    return train_test_split(X, y, test_size=0.6)\n",
    "\n",
    "\n",
    "def result_compare(model):\n",
    "    if model == \"randomForest\":\n",
    "        model = RandomForestClassifier()\n",
    "    elif model == \"svm\":\n",
    "        model = svm.SVC()\n",
    "    elif model == \"reg\":\n",
    "        model = LogisticRegression()\n",
    "    elif model == \"gaussian\":\n",
    "        model = GaussianNB()\n",
    "    elif model == \"hmm\":\n",
    "        model = GaussianHMM()\n",
    "    else:\n",
    "        print(\"无法识别的模型名\")\n",
    "        return\n",
    "    \n",
    "    # ground truth\n",
    "    clf = model\n",
    "    clf.fit(X_real_train, y_real_train)\n",
    "    y_real_pred = clf.predict(X_real_test)\n",
    "    print(\"ground truth 的结果:\")\n",
    "    print(classification_report(y_real_test, y_real_pred))\n",
    "    print(\"--------------------------------------\")\n",
    "\n",
    "\n",
    "    # Original\n",
    "    clf = model\n",
    "    clf.fit(X_original_train, y_original_train)\n",
    "    y_original_pred = clf.predict(X_real_test)\n",
    "    print(\"Metric - Original 的结果:\")\n",
    "    print(classification_report(y_real_test, y_original_pred))\n",
    "    print(\"--------------------------------------\")\n",
    "\n",
    "\n",
    "    # New\n",
    "    clf = model\n",
    "    clf.fit(X_new_train, y_new_train)\n",
    "    y_new_pred = clf.predict(X_real_test)\n",
    "    print(\"Metric - New 的结果:\")\n",
    "    print(classification_report(y_real_test, y_new_pred))\n",
    "    print(\"--------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### REAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 13) (2000,)\n",
      "labels 分布\n",
      "0    1142\n",
      "1     858\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "GROUND_TRUTH_X_PATH = \"/Users/luminshen/Documents/代码/PycharmProjects/Research/-GAN-/Table-GAN/tableGAN/data/Ticket/Ticket.csv\"\n",
    "GROUND_TRUTH_y_PATH = \"/Users/luminshen/Documents/代码/PycharmProjects/Research/-GAN-/Table-GAN/tableGAN/data/Ticket/Ticket_labels.csv\"\n",
    "\n",
    "X_real = np.array(pd.read_csv(GROUND_TRUTH_X_PATH, sep=','))\n",
    "y_real = np.array(pd.read_csv(GROUND_TRUTH_y_PATH, sep=',').astype(int)).flatten()\n",
    "#  去除 hours-per-week 这一列，因为它被用来生成 labels\n",
    "X_real = np.delete(X_real, -2, 1)\n",
    "print(X_real.shape, y_real.shape)\n",
    "print(\"labels 分布\")\n",
    "print(count(y_real))\n",
    "\n",
    "X_real_train, X_real_test, y_real_train, y_real_test = split_data(X_real, y_real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### FAKE-ORIGINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 13) (2000,)\n",
      "labels 分布\n",
      "0     941\n",
      "1    1059\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "FAKE_ORIGINAL_X_PATH = \"/Users/luminshen/Desktop/模型/original gan/Ticket/Ticket_OI_11_00_fake.csv\"\n",
    "\n",
    "X_original, y_original = deal_with_fake_data(FAKE_ORIGINAL_X_PATH)\n",
    "X_original_train, X_original_test, y_original_train, y_original_test = split_data(X_original, y_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### new gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 13) (2000,)\n",
      "labels 分布\n",
      "0    1055\n",
      "1     945\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "FAKE_NEW_X_PATH = \"/Users/luminshen/Desktop/模型/new gan/0相同，10相同/600分钟 w2/Adult_OI_11_00_fake.csv\"\n",
    "\n",
    "X_new, y_new = deal_with_fake_data(FAKE_NEW_X_PATH)\n",
    "X_new_train, X_new_test, y_new_train, y_new_test = split_data(X_new, y_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground truth 的结果:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.76      0.74       684\n",
      "           1       0.66      0.62      0.64       516\n",
      "\n",
      "    accuracy                           0.70      1200\n",
      "   macro avg       0.69      0.69      0.69      1200\n",
      "weighted avg       0.70      0.70      0.70      1200\n",
      "\n",
      "--------------------------------------\n",
      "Metric - Original 的结果:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.44      0.49       684\n",
      "           1       0.43      0.56      0.49       516\n",
      "\n",
      "    accuracy                           0.49      1200\n",
      "   macro avg       0.50      0.50      0.49      1200\n",
      "weighted avg       0.51      0.49      0.49      1200\n",
      "\n",
      "--------------------------------------\n",
      "Metric - New 的结果:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.63      0.60       684\n",
      "           1       0.43      0.38      0.40       516\n",
      "\n",
      "    accuracy                           0.52      1200\n",
      "   macro avg       0.50      0.50      0.50      1200\n",
      "weighted avg       0.51      0.52      0.52      1200\n",
      "\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "result_compare(\"randomForest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground truth 的结果:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.81      0.79       684\n",
      "           1       0.73      0.66      0.69       516\n",
      "\n",
      "    accuracy                           0.75      1200\n",
      "   macro avg       0.74      0.74      0.74      1200\n",
      "weighted avg       0.75      0.75      0.75      1200\n",
      "\n",
      "--------------------------------------\n",
      "Metric - Original 的结果:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.40      0.48       684\n",
      "           1       0.44      0.63      0.52       516\n",
      "\n",
      "    accuracy                           0.50      1200\n",
      "   macro avg       0.52      0.51      0.50      1200\n",
      "weighted avg       0.53      0.50      0.50      1200\n",
      "\n",
      "--------------------------------------\n",
      "Metric - New 的结果:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.70      0.65       684\n",
      "           1       0.51      0.41      0.45       516\n",
      "\n",
      "    accuracy                           0.57      1200\n",
      "   macro avg       0.56      0.55      0.55      1200\n",
      "weighted avg       0.57      0.57      0.57      1200\n",
      "\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "result_compare( \"svm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground truth 的结果:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.82      0.79       684\n",
      "           1       0.74      0.66      0.70       516\n",
      "\n",
      "    accuracy                           0.75      1200\n",
      "   macro avg       0.75      0.74      0.74      1200\n",
      "weighted avg       0.75      0.75      0.75      1200\n",
      "\n",
      "--------------------------------------\n",
      "Metric - Original 的结果:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.42      0.48       684\n",
      "           1       0.43      0.59      0.50       516\n",
      "\n",
      "    accuracy                           0.49      1200\n",
      "   macro avg       0.50      0.50      0.49      1200\n",
      "weighted avg       0.51      0.49      0.49      1200\n",
      "\n",
      "--------------------------------------\n",
      "Metric - New 的结果:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.60      0.60       684\n",
      "           1       0.47      0.47      0.47       516\n",
      "\n",
      "    accuracy                           0.54      1200\n",
      "   macro avg       0.53      0.53      0.53      1200\n",
      "weighted avg       0.54      0.54      0.54      1200\n",
      "\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "result_compare(\"reg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground truth 的结果:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.38      0.51       684\n",
      "           1       0.51      0.84      0.63       516\n",
      "\n",
      "    accuracy                           0.58      1200\n",
      "   macro avg       0.63      0.61      0.57      1200\n",
      "weighted avg       0.65      0.58      0.56      1200\n",
      "\n",
      "--------------------------------------\n",
      "Metric - Original 的结果:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.48      0.51       684\n",
      "           1       0.39      0.45      0.42       516\n",
      "\n",
      "    accuracy                           0.47      1200\n",
      "   macro avg       0.47      0.46      0.46      1200\n",
      "weighted avg       0.47      0.47      0.47      1200\n",
      "\n",
      "--------------------------------------\n",
      "Metric - New 的结果:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.45      0.52       684\n",
      "           1       0.46      0.62      0.53       516\n",
      "\n",
      "    accuracy                           0.53      1200\n",
      "   macro avg       0.54      0.54      0.52      1200\n",
      "weighted avg       0.55      0.53      0.52      1200\n",
      "\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "result_compare(\"gaussian\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "def get_kldiverge(data_1, data_2):\n",
    "    if data_1.split(\"/\")[-1] == \"Adult.csv\":\n",
    "        A = np.array(pd.read_csv(data_1, sep=',')).astype(float)\n",
    "    else:\n",
    "        A = np.array(pd.read_csv(data_1, sep=';')).astype(float)\n",
    "        \n",
    "    if data_2.split(\"/\")[-1] == \"Adult.csv\":\n",
    "        B = np.array(pd.read_csv(data_2, sep=',')).astype(float)\n",
    "    else:\n",
    "        B = np.array(pd.read_csv(data_2, sep=';')).astype(float)\n",
    "\n",
    "    KL = scipy.stats.entropy(A, B) \n",
    "    \n",
    "#     print(KL)\n",
    "    \n",
    "    res = 0\n",
    "    count = 0\n",
    "    for kl in KL:\n",
    "        if kl != float('inf'):\n",
    "            res += kl\n",
    "            count += 1\n",
    "            \n",
    "    return res/count\n",
    "\n",
    "def get_mse(data_1, data_2):\n",
    "    if data_1.split(\"/\")[-1] == \"Adult.csv\":\n",
    "        A = np.array(pd.read_csv(data_1, sep=',')).astype(float)\n",
    "    else:\n",
    "        A = np.array(pd.read_csv(data_1, sep=';')).astype(float)\n",
    "        \n",
    "    if data_2.split(\"/\")[-1] == \"Adult.csv\":\n",
    "        B = np.array(pd.read_csv(data_2, sep=',')).astype(float)\n",
    "    else:\n",
    "        B = np.array(pd.read_csv(data_2, sep=';')).astype(float)\n",
    "    \n",
    "#     print(A.shape, B.shape)\n",
    "    X = np.append(A, B, axis=0)\n",
    "    y = np.append(np.zeros(A.shape[0]), np.ones(B.shape[0]))\n",
    "#     print(X.shape, y.shape)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7, random_state=1)\n",
    "\n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict_proba(X_train)\n",
    "    \n",
    "    # 计算 MSE\n",
    "    c = 0.5\n",
    "    res = 0\n",
    "    for i in range(X.shape[0]):\n",
    "        res += (y_pred[0][0] - 0.5)**2\n",
    "    \n",
    "    print(res/X.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### kl diverge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20904159718322513\n",
      "0.2201262291237125\n",
      "0.22591861288510268\n"
     ]
    }
   ],
   "source": [
    "GROUND_TRUTH_PATH = \"/Users/luminshen/Documents/代码/PycharmProjects/Research/-GAN-/Table-GAN/tableGAN/data/Adult/Adult.csv\"\n",
    "FAKE_ORIGINAL_PATH = \"/Users/luminshen/Desktop/模型/original gan/300分钟/Adult_OI_11_00_fake.csv\"\n",
    "FAKE_NEW_PATH = \"/Users/luminshen/Desktop/模型/new gan/0相同，10相同/600分钟 w2/Adult_OI_11_00_fake.csv\"\n",
    "\n",
    "print(get_kldiverge(GROUND_TRUTH_PATH, FAKE_ORIGINAL_PATH))\n",
    "print(get_kldiverge(GROUND_TRUTH_PATH, FAKE_NEW_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Propensity Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2437295345205261\n",
      "0.007858005889236299\n",
      "0.02659079155609898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luminshen/Documents/代码/PycharmProjects/Research/-GAN-/venv/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "get_mse(GROUND_TRUTH_PATH, FAKE_ORIGINAL_PATH)\n",
    "get_mse(GROUND_TRUTH_PATH, FAKE_NEW_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
